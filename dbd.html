<!DOCTYPE HTML>
<!--
	Forty by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Nicholas Bandy</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
				<!-- Note: The "styleN" class below should match that of the banner element. -->
					<header id="header" class="alt style2">
						<a href="index.html" class="logo"><strong>Nicholas Bandy</strong></a>
						<nav>
							<a href="#menu">Menu</a>
						</nav>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<li><a href="dbd.html">Deciphering Big Data</a></li>
						</ul>
						
					</nav>

				<!-- Banner -->
				<!-- Note: The "styleN" class below should match that of the header element. -->
					<section id="banner" class="style2">
						<div class="inner">
							<span class="image">
								<img src="images/pic07.jpg" alt="" />
							</span>
							<header class="major">
								<h1>Deciphering Big Data</h1>
							</header>
						</div>
					</section>

				<!-- Main -->
					<div id="main">

						<!-- One -->
							<section id="one">
								<div class="inner">
									<header class="major">
										<h2>Unit 1-3 Discussion</h2>
									</header>
									<p>Discussing this topic with my classmates has helped me identify some of the challenges posed by data generated by IoT and understand the best approaches for solving these challenges.

<p>While it was pointed out that the use of IoT suggests data should be well defined and therefore ready for analysis, there are often external factors which compromise the integrity of the data (Ardagna, 2021). This is an issue that I often come across in my work as a data analyst, where IoT systems are in place to gather data with the expectation that it can be easily used. After receiving the data it is clear that there are inconsistencies, and that more data cleaning is still required. I’ve been seeing this mostly with GPS coordinates in areas with tall buildings due to reflections off of the buildings, and in cases where infrared sensors are used to count the number of people passing a point due to aging hardware or large volumes of people clumped together.</p>

<p>As Mika correctly identified, manual correction of these big datasets will be very time consuming and costly (Bobluski & Kubanek, 2022). Using a statistics-based approach for cleaning these datasets can help save on both time and cost and is especially useful in ensuring that the data cleaning happens as early as possible without additional manual effort. This allows it to be used in real-time reporting, which can provide great value to operations in being able to understand the current state of their operation.</p>
										
<p>The best statistic-based approach will vary depending on the dataset itself, but spending the time to understand the problem and find an automated data cleaning approach will help prevent future costly and time-consuming manual workload.</p>

  

<p>References</p>

<p>Bobluski, J. & Kubanek, M. (2022) A method of cleaning data from IoT devices in big data systems. IEEE International Conference on Big Data. 2022 IEEE International Conference on Big Data (Big Data), 6596-6598. Available From: DOI: 10.1109/BigData55660.2022.10020651</p>

<p>Ardagna, C.; Asal, R.;  Damiani, E.; Ioini, N.; Elahi, M.; Pahl, C.. (2021). From Trustworthy Data to Trustworthy IoT: A Data Collection Methodology Based on Blockchain. ACM Trans. Cyber-Phys. Syst. 5, 1, Article 11 (January 2021), 26 pages. Available From: https://doi-org.uniessexlib.idm.oclc.org/10.1145/3418686</p></p>
								</div>
							</section>

						<!-- Two -->
						<section id="two">
								<div class="inner">
									<header class="major">
										<h2>Unit 3 Web Scraping Activity</h2>
									</header>
									<p>The purpose of this task was to build a web scraper using Python to find the word "Data Scientist" and save the results in a json file. This task was my first attempt at building a web scraper, and aves the string containg the string "data scientist" along with its parent tag in a json file.</p>
									<p>Writing this script was my first exposure to making http requests and parsing the data on a webpage. I expect that this skill will be extremely valuable in the future, due to the large amounts of data stored online. To advance my script further, a next step could be to split the text into sentences to retrieve all sentences containing the keyword instead of the entire string.</p>
									<a href="https://github.com/Nicholas-Bandy/eportfolio/blob/main/Web_Scraping_Text_Finder.py">View the web scraper here</a>
								</div>
							</section>

						<!-- Three -->
						<section id="three">
								<div class="inner">
									<header class="major">
										<h2>Unit 4 Data Cleaning Activity</h2>
									</header>
									<p>Data cleaning is a crucial step to any project. During the data cleaning process we must find and correct any missing data, inconsistencies, or any errors that exist within the data set. If the process is skipped, any result obtained from working with the dataset is subject to the influence of inaccurate data. In this unit, we followed the data cleaning activity in the ebook "Data Wrangling With Python" as listed in the lecturecast. This unit focused on the use of the pandas library to import and clean a dataset. In this activity we identified duplicate rows and missing values from the desired columns in the dataset. This exercise was useful in practicing programming with python, while learning how to clean and transform a pandas dataframe.</p>
									</div>
							</section>
						
						<!-- Four -->
						<section id="four">
								<div class="inner">
									<header class="major">
										<h2>Unit 6 Database Design Proposal</h2>
									</header>
									<p>In this assignment our task was to propose a database design Uni Prep Ltd based on their requirements to store student, staff, and course related data.</p>
									<p>My work in the project involved creating the proposed design based on the research and surveys completed by my team members. I was able to apply the normalisation techniques learned in the Unit 6 lecturecast and readings to propose a database design that met all client requirements. While doing this, I needed to consider all possible uses for the databases, such as how new students or classes could be added, how to efficiently select a set of information, and how personal information could be removed from the database with this design.</p>
									<p>Tutor Feedback:</p>
									<p>Knowledge and understanding of the topic/ issues under consideration An outstanding demonstration of knowledge and understanding, displaying originality and an advanced understanding of the topic relevant to the work. The report is very precise with defining the application, listing client requirements, then offering a suitable design. The use of user survey to guide the design is excellent. Application of knowledge and understanding An excellent demonstration of the application of knowledge and understanding to address the requirements including a real-world application. The application is a database for a private education company, and there are good insights requirements, reasoning, data pipeline tasks, and design. However, the model design is simply depicted in Figure 1 and no real explanation of that figure is given - although a main requirement. Criticality A excellent demonstration of critical analysis throughout, with very good linking between theory and practice. There is a good list of references in Harvard style that are well cited to focus arguments where appropriate. Structure and Presentation (as detailed in the assessment guidance) A very good structure and presentation but has some issues against the guidelines. The report redresses all assessment requirements. The English grammar and spelling are sound. The word count is within limits at 1100 (excluding references and appendix). There are some anomalies in formatting the report, for example number of line spacing that ruin the presentation! Please consider paying attention to such fine details.</p>
									<a href="https://github.com/Nicholas-Bandy/eportfolio/blob/main/Project Report - Database design FINAL.pdf">View the full report here</a>
								</div>
							</section>
						<!-- Five -->
							<section id="five">
								<div class="inner">
									<header class="major">
										<h2>Unit 8-10 Discussion</h2>
									</header>
									<p>With collecting and storing large amounts of data becoming easier by the year, many people are becoming more concerned about how their personal information can be stored and used. The GDPR (Regulation, 2016/679) is a framework implemented in the EU to regulate data protection practices between varying countries and organizations. The GDPR applies to anybody who is processing or controlling personal data (Vigt & Van Dem Bussche, 2017).</p>

<p>In Canada, PIPEDA is the legislation in place to protect personal information and was put in place as a response to the 1995 EU Data Protection Directive (Bolca, 2020). Unlike the GDPR which applies to all bodies who process or control personal data, PIPEDA only applies to the commercial use of personal information (Nisker, 2006). Therefore, Public bodies are not included within the scope of PIPEDA, and instead fall under a provincial Freedom of Information and Privacy Act. The Freedom of Privacy and Information Act covers the access and privacy of information for the public sector, and is often used to increase transparency and accountability for government agencies (Berzins, 2014). The Freedom of Information and Privacy Act allows any individual to request any non-sensitive data from a government agency, and prevents the agency from revealing personal information.</p>



<p>References</p>

<p>Berzins, C. (2014). Ontario's freedom of information and protection of privacy act after 25 years: critical assessment. Advocates' Quarterly, 43(1), 80-110. Available from https://heinonline-org.uniessexlib.idm.oclc.org/HOL/Page?handle=hein.journals/aqrty43&id=84&collection=journals&index=</p>

<p>Bolca, T. (2020) "Can PIPEDA ‘Face’ the Challenge? An Analysis of the Adequacy of Canada’s Private Sector Privacy Legislation against Facial Recognition Technology"  Available From https://digitalcommons.schulichlaw.dal.ca/cgi/viewcontent.cgi?article=1262&context=cjlt</p>

<p>European Parliament and of the Council (2016). GDPR Regulation at: Regulation (EU) 2016/679. Available From: https://eur-lex.europa.eu/legal-content/EN/TXT/?qid=1532348683434&uri=CELEX:02016R0679-20160504</p>

<p>Nisker, J. (2006). Pipeda: constitutional analysis. Canadian Bar Review, 85(2), 317-344. Available from https://heinonline-org.uniessexlib.idm.oclc.org/HOL/Page?collection=journals&handle=hein.journals/canbarev85&id=317&men_tab=srchresults</p>

<p>Voigt, P. and Von Dem Bussche, A. (2017). Scope of Application of the GDPR. In: , 9–30. Available from https://link-springer-com.uniessexlib.idm.oclc.org/chapter/10.1007/978-3-319-57959-7_2</p>
								
								</div>
							</section>
						
							<!-- Six -->
						<section id="six">
								<div class="inner">
									<header class="major">
										<h2>Unit 11 Database Executive Summary</h2>
									</header>
									<p>In this assignment, we were required to provide an executive summary on the final database build from Unit 6. For this assignment I used Pythons sqlite3 library to create the proposed database from Unit 6, and load it with a sample dataset for testing. This Python script can be found here: <a href="https://github.com/Nicholas-Bandy/eportfolio/blob/main/builddbpython.py">builddbpython.py</a></p>
									<p>After the database was created I wrote some sample queries to perform some of the actions highlighted in the requirements. These covered adding, deleting, slecting, or updating data from the database. This script can be found here: <a href="https://github.com/Nicholas-Bandy/eportfolio/blob/main/db_queries.py">builddb.py</a></p>
									<p>Our final build followed closely along the initial proposal in terms of design, however we switched from an azure build to SQlite as it was more practical for this assignment. We expect that once the client is able to provide a real sample dataset that some changes to the proposed structure may be required</p>
									<a href="https://github.com/Nicholas-Bandy/eportfolio/blob/main/Executive summary - FINAL.pdf">View the final report here</a>
								</div>
							</section>

					</div>

				<!-- Contact -->
					<section id="contact">
						<div class="inner">
							<section>
								<form method="post" action="#">
									<div class="fields">
										<div class="field half">
											<label for="name">Name</label>
											<input type="text" name="name" id="name" />
										</div>
										<div class="field half">
											<label for="email">Email</label>
											<input type="text" name="email" id="email" />
										</div>
										<div class="field">
											<label for="message">Message</label>
											<textarea name="message" id="message" rows="6"></textarea>
										</div>
									</div>
									<ul class="actions">
										<li><input type="submit" value="Send Message" class="primary" /></li>
										<li><input type="reset" value="Clear" /></li>
									</ul>
								</form>
							</section>
							<section class="split">
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-envelope"></span>
										<h3>Email</h3>
										<a href="#">nicholasbandy1@gmail.com</a>
									</div>
								</section>
								
							</section>
						</div>
					</section>

				<!-- Footer -->
					<footer id="footer">
						<div class="inner">
							<ul class="icons">
								<li><a href="#" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>
								<li><a href="#" class="icon brands alt fa-facebook-f"><span class="label">Facebook</span></a></li>
								<li><a href="#" class="icon brands alt fa-instagram"><span class="label">Instagram</span></a></li>
								<li><a href="#" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
								<li><a href="#" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
							</ul>
							<ul class="copyright">
								<li>&copy; Untitled</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
